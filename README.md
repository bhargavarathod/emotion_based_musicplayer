# emotion_based_musicplayer
Emotion_classification is the .ipynb file where we have used google collab to train the model by using VGG16 architecture.
Emotion_detection is a .ipynb file where we have loaded the saved trained model and compare it with the frames captures from the webcam using CV2. 
And detect the facial emotion and plays the relevant songs based on the emotion captured.
You can directly upload the emotion_classification.ipynb in google collab and you are ready to use.
you can directly upload the emotion_detection.ipynb file into the jupyter notebook and install the required packages and you are ready to go.
